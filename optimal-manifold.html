<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Eddie Cunningham" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Blog, " />

<meta property="og:title" content="Optimal manifold "/>
<meta property="og:url" content="/optimal-manifold.html" />
<meta property="og:description" content="Optimal manifolds and VAEs" />
<meta property="og:site_name" content="" />
<meta property="og:article:author" content="Eddie Cunningham" />
<meta property="og:article:published_time" content="2023-12-08T00:00:00-05:00" />
<meta name="twitter:title" content="Optimal manifold ">
<meta name="twitter:description" content="Optimal manifolds and VAEs">

        <title>Optimal manifold  Â· 
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="/"><span class=site-name></span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       "/"
                                    >Home</a>
                                </li>
                                <li ><a href="/pages/about.html">About</a></li>
                                <li ><a href="/pages/research.html">Research</a></li>
                                <li ><a href="/categories.html">Categories</a></li>
                                <li ><a href="/tags.html">Tags</a></li>
                                <li ><a href="/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="/optimal-manifold.html">
                Optimal manifold
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>In this post we'll be looking at a notion of optimality for manifolds from <a href="https://proceedings.neurips.cc/paper_files/paper/2003/file/bc7f621451b4f5df308a8e098112185d-Paper.pdf">Chigirev and Bialek</a>.</p>
<h1>Problem setting</h1>
<p>Suppose that we have data <span class="math">\(x\)</span> that follows the distribution <span class="math">\(p(x)\)</span> and we want to find an encoding of the data <span class="math">\(z\)</span> that is lower dimensional than <span class="math">\(x\)</span> but still captures the important information in <span class="math">\(x\)</span>.  We will want to find an encoding distribution, <span class="math">\(q(z|x)\)</span> and a function <span class="math">\(f(z)\)</span> that maps the encoding to the data such that <span class="math">\(f(z)\)</span> (measured by distortion) while keeping a fixed capacity needed to transmit the encoding (measured by mutual information).</p>
<h2>Distortion</h2>
<p>There will be some loss invovled in this process which we will measure with the concept of distortion.  Suppose that we have a function that measures how similar two points are, <span class="math">\(d(x,f(z))\)</span>.  Then the distortion is defined as:</p>
<div class="math">$$
\begin{align}
  D = \mathbb{E}_{p(x)q(z|x)}\left[d(x,f(z))\right]
\end{align}
$$</div>
<p>
In order for the math to work out nicely, we can choose <span class="math">\(d=\frac{1}{2}\|x-f(z)\|^2\)</span>.</p>
<h2>Mutual information</h2>
<p>We also want to ensure that the encoding is efficient, i.e. the mutual information between the encoding and the data is maximized.  This is defined as:</p>
<div class="math">$$
\begin{align}
  I = \mathbb{E}_{p(x)q(z|x)}\left[\log \frac{q(z|x)}{q(z)}\right]
\end{align}
$$</div>
<p>
where <span class="math">\(q(z) = \int p(x)q(z|x)dx\)</span> is the marginal under the model.</p>
<h2>Optimal manifold</h2>
<p>We want to find the optimal <span class="math">\(f\)</span> so that the distortion is minimized while the mutual information is fixed.  <a href="https://proceedings.neurips.cc/paper_files/paper/2003/file/bc7f621451b4f5df308a8e098112185d-Paper.pdf">Chigirev and Bialek</a> pose this as the solution of the optimization problem
</p>
<div class="math">$$
\begin{align}
  F(f,q) = D(f,q) + \lambda I(q)
\end{align}
$$</div>
<p>
We can solve this problem without using functional calculus by parametrizing <span class="math">\(f\)</span> and <span class="math">\(q\)</span> with the parameters <span class="math">\(\theta\)</span> and <span class="math">\(\phi\)</span> respecitvely and then set gradients to 0:
</p>
<div class="math">$$
\begin{align}
  F(\theta,\phi) = D(\theta,\phi) + \lambda I(\phi)
\end{align}
$$</div>
<h3>Optimal decoder function</h3>
<p>Lets derive the gradients of <span class="math">\(F\)</span> with respect to <span class="math">\(\theta\)</span> first.</p>
<div class="math">$$
\begin{align}
  \nabla_\theta F(\theta,\phi) &amp;= \nabla_\theta D(\theta,\phi) \\
  &amp;= \nabla_\theta \mathbb{E}_{p(x)q(z|x)}\left[\frac{1}{2}\|x-f_\theta(z)\|^2\right] \\
  &amp;= \mathbb{E}_{p(x)q(z|x)}\left[\nabla_\theta \frac{1}{2}\|x-f_\theta(z)\|^2\right] \\
  &amp;= \mathbb{E}_{p(x)q(z|x)}\left[(x-f_\theta(z))\nabla_\theta f_\theta(z)\right] \\
  &amp;= \mathbb{E}_{q(z)p(x|z)}\left[(x-f_\theta(z))\nabla_\theta f_\theta(z)\right] \\
  &amp;= \mathbb{E}_{q(z)}\left[(\mathbb{E}_{p(x|z)}[x]-f_\theta(z))\nabla_\theta f_\theta(z)\right]
\end{align}
$$</div>
<p>
Therefore, in order to get a gradient of <span class="math">\(0\)</span>, we would need
</p>
<div class="math">$$
\begin{align}
  f_\theta(z) = \mathbb{E}_{p(x|z)}[x]
\end{align}
$$</div>
<p>
where <span class="math">\(p(x|z) = \frac{p(x)q(z|x)}{q(z)}\)</span> is the conditional under the model.</p>
<h3>Optimal encoder distribution</h3>
<p>Next, lets look at the gradient with respect to <span class="math">\(\phi\)</span>:
</p>
<div class="math">$$
\begin{align}
\nabla_\phi F(\theta,\phi) &amp;= \nabla_\phi D(\theta,\phi) + \lambda I(\phi) \\
&amp;= \nabla_\phi \mathbb{E}_{p(x)q_\phi(z|x)}\left[\frac{1}{2}\|x-f(z)\|^2 + \lambda \log \frac{q_\phi(z|x)}{q_\phi(z)}\right] \\
&amp;= \mathbb{E}_{p(x)q_\phi(z|x)}\left[\nabla_\phi \log q_\phi(z|x)(\frac{1}{2}\|x-f(z)\|^2 + \lambda \log \frac{q_\phi(z|x)}{q_\phi(z)})\right] + \lambda \underbrace{\mathbb{E}_{p(x)q_\phi(z|x)}\left[\nabla_\phi \log \frac{q_\phi(z|x)}{q_\phi(z)}\right]}_{0}
\end{align}
$$</div>
<p>
The last part of the equation is 0 because
</p>
<div class="math">$$
\begin{align}
\mathbb{E}_{p(x)q_\phi(z|x)}[\nabla_\phi \log q_\phi(z|x)] &amp;= \mathbb{E}_{p(x)}\int \nabla_\phi q_\phi(z|x)dz \\
&amp;= \mathbb{E}_{p(x)}\nabla_\phi 1 \\
&amp;= 0
\end{align}
$$</div>
<p>
and
</p>
<div class="math">$$
\begin{align}
\mathbb{E}_{p(x)q_\phi(z|x)}[\nabla_\phi \log q_\phi(z)] &amp;= \mathbb{E}_{q_\phi(z)}[\nabla_\phi \log q_\phi(z)] \\
&amp;= \nabla_\phi 1 \\
&amp;= 0
\end{align}
$$</div>
<p>
So in order to get a gradient of <span class="math">\(0\)</span>, we would need
</p>
<div class="math">$$
\begin{align}
  \log q_\phi(z|x) = -\frac{1}{2\lambda}\|x - f(z)\|^2 + \log q_\phi(z) - \log Z(x)
\end{align}
$$</div>
<p>
where <span class="math">\(\log Z(x)\)</span> is a normalization constant (any constant that doesn't depend on <span class="math">\(z\)</span> will have an expectation of <span class="math">\(0\)</span> and can be added without changing the gradient).  Note that <span class="math">\(-\frac{1}{2\lambda}\|x - f(z)\|^2 = \log N(x|f(z),\lambda I) + \text{const}\)</span>.  This implies that the similarity function <span class="math">\(d(x,f(z))\)</span> can be interpreted as the negative log likelihood of <span class="math">\(x\)</span>.  This means that the distribution <span class="math">\(p(x|z)\)</span> that appears in the expression for <span class="math">\(f\)</span> is <span class="math">\(N(x|f(z),\lambda I)\)</span>.</p>
<p>So in summary, we have that the optimal <span class="math">\(f\)</span> and <span class="math">\(q\)</span> are given by
</p>
<div class="math">$$
\begin{align}
  f(z) &amp;= \mathbb{E}_{N(x|f(z),\lambda I)}[x] \\
  q(z|x) &amp;= \frac{N(x|f(z),\lambda I)q(z)}{Z(x)}
\end{align}
$$</div>
<p>
A way to interpret this is that the generating process for the data is <span class="math">\(z\sim q(z)\)</span> and then <span class="math">\(x\sim N(x|f(z),\lambda I)\)</span>.</p>
<h3>General distance function</h3>
<p>We can keep the interpretation that the optimal encoding distribution is a posterior distribution by identifying the similarity function <span class="math">\(d(x,f(z))\)</span> as the negative log likelihood of a data generating process, <span class="math">\(-\log p_\lambda(x|f(z))\)</span>.  The optimal <span class="math">\(q(z|x)\)</span> is still the posterior:
</p>
<div class="math">$$
\begin{align}
  q(z|x) &amp;= \frac{p_\lambda(x|z)q(z)}{Z(x)}
\end{align}
$$</div>
<p>
However, the optimal manifold might not be something we can solve for analytically.  <span class="math">\(f(z)\)</span> will be a function that satisfies
</p>
<div class="math">$$
\begin{align}
  0 &amp;= \mathbb{E}_{p(x)q(z|x)}\left[\nabla_\theta \log p_\lambda(x|f(z))\right]
\end{align}
$$</div>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
            
            
            






            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2023-12-08T00:00:00-05:00">Dec 8, 2023</time>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#blog-ref">Blog</a>
            





            





        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>