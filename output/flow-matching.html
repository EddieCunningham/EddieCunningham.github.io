<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Eddie Cunningham" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="flows, matching, generative models, Blog, " />

<meta property="og:title" content="Flow matching "/>
<meta property="og:url" content="/flow-matching.html" />
<meta property="og:description" content="A tutorial on flow matching" />
<meta property="og:site_name" content="The Weeds" />
<meta property="og:article:author" content="Eddie Cunningham" />
<meta property="og:article:published_time" content="2023-07-15T00:00:00-05:00" />
<meta property="og:article:modified_time" content="2023-07-15T00:00:00-05:00" />
<meta name="twitter:title" content="Flow matching ">
<meta name="twitter:description" content="A tutorial on flow matching">

        <title>Flow matching  Â· The Weeds
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="/"><span class=site-name>The Weeds</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       "/"
                                    >Home</a>
                                </li>
                                <li ><a href="/pages/about.html">About</a></li>
                                <li ><a href="/categories.html">Categories</a></li>
                                <li ><a href="/tags.html">Tags</a></li>
                                <li ><a href="/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="/flow-matching.html">
                Flow matching
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>Flow matching is probably the most important contribution to the field of normalizing flows in the last few years.  It allows us to train continuous normalizing flows in a simulation free way while also avoiding the pitfalls that comes with working with likelihoods.  In this tutorial, we'll go over what flow matching is and some of its practical properties.</p>
<h1>Overview</h1>
<p>Say that we are trying to learn a parametric approximation of an unknown probability distribution that we can sample from.  The first <a href="https://arxiv.org/pdf/2210.02747.pdf">flow matching paper</a> showed how we can <strong>construct</strong> a continuous normalizing flow that generates this target from any user specified prior.  Moreover, this flow that we can write down is something that we can use as a target to train a parametric model against.  This training algorithm does not suffer from the common pitfalls that maximum likelihood or score matching suffer from because it does not require us to compute likelihoods or score functions.  If you're not familiar with continuous normalizing flows, check out <a href="continuous_normalizing_flows.md">my post</a> on them.</p>
<h1>CNF construction</h1>
<p>Here, we'll show how we can <strong>construct</strong> the continuous normalizing flow that generates a target distribution from any user specified prior.  Let <span class="math">\(p_1:=p_\text{data}\)</span> be the target distribution that we want to learn and let <span class="math">\(p_0\)</span> be a user specified prior.  We'll start by assuming that there is a probability path between <span class="math">\(p_0\)</span> and <span class="math">\(p_1\)</span>, denoted by <span class="math">\(p_t\)</span>, that is generated by the flow of a time dependent vector field <span class="math">\(V_t\)</span>.  Our goal will be to show what the equation of <span class="math">\(V_t\)</span> is.</p>
<p>To do this, we will assume that <span class="math">\(p_t\)</span> is actually a marginal probability distribution over <span class="math">\(x_t\)</span> and some random variable <span class="math">\(y\)</span>:
</p>
<div class="math">$$
\begin{align}
  p_t(x_t) = \int p_y(y)p_{t|y}(x_t|y) dy
\end{align}
$$</div>
<p>
where <span class="math">\(p_y(y)\)</span> and <span class="math">\(p_{t|y}(x_t|y)\)</span> are chosen so that <span class="math">\(p_{t=0} = p_0\)</span> and <span class="math">\(p_{t=1} = p_\text{data}\)</span>.  Next, we assume that there is a CNF that generates <span class="math">\(p_{t|y}(x_t|y)\)</span> using a vector field <span class="math">\(\tilde{V}_t(x_t|y)\)</span> that takes <span class="math">\(y\)</span> as a parameter.  The key insight that the flow matching paper makes is that we can write <span class="math">\(V_t(x_t)\)</span> as the expected value of <span class="math">\(\tilde{V}_t(x_t|y)\)</span> over the posterior distribution of <span class="math">\(y\)</span> given <span class="math">\(x_t\)</span>:
</p>
<div class="math">$$
\begin{align}
V_t(x_t) &amp;= \int \frac{p_y(y)p_{t|y}(x_t|y)}{p_t(x_t)}\tilde{V}_t(x_t|y) dy \\
&amp;= \mathbb{E}_{p_{t|y}(y|x_t)}[\tilde{V}_t(x_t|y)]
\end{align}
$$</div>
<p>
We can check that this is true by checking that the continuity equation is satisfied:
</p>
<div class="math">$$
\begin{align}
  \frac{\partial p_t}{\partial t} &amp;= \frac{d}{dt}\int p_y(y)p_{t|y}(x_t|y) dy \\
  &amp;= \int p_y(y)\frac{d}{dt}p_{t|y}(x_t|y) dy \\
\end{align}
$$</div>
<p>Thus, we have constructed a continuous normalizing flow that takes <span class="math">\(p_0\)</span> to <span class="math">\(p_1=p_\text{data}\)</span>.  So far this doesn't seem too useful, but there are two reasons main reasons that will lead us to a simulation free training algorithm:</p>
<ol>
<li>
<p>We can get easy unbiased estimates of the expected vector field as follows:
  <div class="math">$$
  \begin{align}
  \mathbb{E}_{p_t(x_t)}[V_t(x_t)] &amp;= \int p_t(x_t)V_t(x_t) dx_t \\
  &amp;= \int p_t(x_t)\mathbb{E}_{p_{t|y}(y|x_t)}[\tilde{V}_t(x_t|y)] dx_t \\
  &amp;= \int \int p_t(x_t)p_{t|y}(y|x_t)\tilde{V}_t(x_t|y) dx_t dy \\
  &amp;= \int \int p_y(y)p_{t|y}(x_t|y)\tilde{V}_t(x_t|y) dx_t dy \\
  &amp;= \mathbb{E}_{p_y(y)p_t(x_t|y)}\left[\tilde{V}_t(x_t|y)\right]
  \end{align}
  $$</div>
</p>
</li>
<li>
<p>There are easy choices of <span class="math">\(p_y(y)\)</span> and <span class="math">\(p_t(x_t|y)\)</span> that we can sample from and know in closed form.  Specifically, we will usually choose <span class="math">\(p_y = p_\text{data}\)</span> and <span class="math">\(p_t(x_t|y)\)</span> to be a Gaussian distribution with mean <span class="math">\(\mu_t(y)\)</span> and covariance <span class="math">\(\Sigma_t(y)\)</span> with conditions on <span class="math">\(\mu_t\)</span> and <span class="math">\(\Sigma_t\)</span> that ensure that <span class="math">\(p_{t=0} = p_0\)</span> and <span class="math">\(p_{t=1} = p_\text{data}\)</span>.</p>
</li>
</ol>
<h1>Flow matching</h1>
<p>Now that we have a way to construct a target continuous normalizing flow whose generating vector field is <span class="math">\(V_t\)</span>, we can train a model to match <span class="math">\(V_t\)</span>.  Let <span class="math">\(W_t\)</span> be a vector field that is parametrized using a neural network whose flow corresponds to the probability density function <span class="math">\(q_t(x_t)\)</span>.  We can train <span class="math">\(W_t\)</span> to match <span class="math">\(V_t\)</span> by minimizing the following loss function:
</p>
<div class="math">$$
\begin{align}
\mathcal{L}_{\text{FM}}(\theta) &amp;= \int_0^1 \mathbb{E}_{p_t(x_t)}\left[\left\|V_t(x_t) - W_t(x_t;\theta)\right\|^2\right] dt \\
&amp;= \small{\underbrace{\int_0^1 \mathbb{E}_{p_t(x_t)}[\|V_t(x_t)\|^2]dt}_{C_1} - 2\int_0^1 \mathbb{E}_{p_t(x_t)}[V_t(x_t)^TW_t(x_t;\theta)]dt + \int_0^1 \mathbb{E}_{p_t(x_t)}[\|W_t(x_t;\theta)\|^2]dt} \\
&amp;= C_1 - 2\int_0^1 \mathbb{E}_{p_t(x_t)}\left[V_t(x_t)\right]^TW_t(x_t;\theta)dt + \int_0^1 \mathbb{E}_{p_t(x_t)}\left[\|W_t(x_t;\theta)\|^2\right]dt \\
&amp;= C_1 - 2\int_0^1 \mathbb{E}_{p_y(y)p_t(x_t|y)}\left[\tilde{V}_t(x_t|y)\right]^TW_t(x_t;\theta)dt + \int_0^1 \mathbb{E}_{p_t(x_t)}\left[\|W_t(x_t;\theta)\|^2\right]dt \\
&amp;= C_1 - C_2 + \underbrace{\int_0^1 \mathbb{E}_{p_y(y)p_t(x_t|y)}\left[\|\tilde{V}_t(x_t|y) - W_t(x_t;\theta)\|^2\right]dt}_{\mathcal{L}_{\text{CFM}}(\theta)}
\end{align}
$$</div>
<p>
where <span class="math">\(C_2 = \int_0^1 \mathbb{E}_{p_y(y)p_t(x_t|y)}\left[\|\tilde{V}_t(x_t|y)\|^2\right]dt\)</span>.  So we can minimize <span class="math">\(\mathcal{L}_{\text{FM}}(\theta)\)</span> by minimizing <span class="math">\(\mathcal{L}_{\text{CFM}}(\theta)\)</span> because <span class="math">\(C_1\)</span> and <span class="math">\(C_2\)</span> are constants.  <span class="math">\(\mathcal{L}_{\text{CFM}}(\theta)\)</span> is called the <strong>conditional flow matching</strong> loss.</p>
<p>We can also reparametrize <span class="math">\(x_t\)</span> with <span class="math">\(f_t(x_t|y)\)</span> to get the following loss function:
</p>
<div class="math">$$
\begin{align}
\mathcal{L}_{\text{CFM}}(\theta) &amp;= \int_0^1 \mathbb{E}_{p_y(y)p_t(x_t|y)}\left[\|\tilde{V}_t(x_t|y) - W_t(x_t;\theta)\|^2\right]dt \\
&amp;= \int_0^1 \mathbb{E}_{p_y(y)p_0(x_0)}\left[\left\|\tilde{V}_t(f_t(x_0)|y) - W_t(f_t(x_0);\theta)\right\|^2\right]dt
\end{align}
$$</div>
<p>In this form, we can see the algorithm needed to train <span class="math">\(W_t(x_t;\theta)\)</span>:
1. Sample <span class="math">\(y\sim p_y(y)\)</span> and <span class="math">\(x_0\sim p_0(x_0)\)</span>
2. Construct some path that starts at <span class="math">\(x_0\)</span> and ends at <span class="math">\(y\)</span>
3. Sample any point on this path (to get <span class="math">\(f_t(x_0)\)</span>) and get the tangent vector at that point (to get <span class="math">\(\tilde{V}_t(f_t(x_0)|y)\)</span>)
4. Compute the loss between <span class="math">\(\tilde{V}_t(f_t(x_0)|y)\)</span> and <span class="math">\(W_t(x_t;\theta)\)</span></p>
<p>This training algorithm will be efficient so long as the path between <span class="math">\(x_0\)</span> and <span class="math">\(x_1\)</span> (which is given by <span class="math">\(f_t(x_0)\)</span>) is easy to compute.  In the next section, we'll go over one possible example of how to do this.</p>
<h1>Conditional optimal transport</h1>
<p>The easiest choice for that we could choose for a path between <span class="math">\(x_0\)</span> and <span class="math">\(y\)</span> is simply a straight line between the two.  This is called the <strong>conditional optimal transport</strong> path and is defined as follows:
</p>
<div class="math">$$
\begin{align}
  f_t(x_0;y) &amp;= (1-t)x_0 + ty \\
  &amp;= x_0 + t(y - x_0)
\end{align}
$$</div>
<p>
The tangent vector to this curve is also trivial to compute:
</p>
<div class="math">$$
\begin{align}
  \frac{df_t(x_0;y)}{dt} &amp;= y - x_0
\end{align}
$$</div>
<p>
So the pseudo code to train a CNF using flow matching with the conditional optimal transport path looks like this</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">flow_matching_objective</span><span class="p">(</span><span class="n">data_batch</span><span class="p">):</span>
  <span class="n">batch_size</span> <span class="o">=</span> <span class="n">data_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">t</span> <span class="o">=</span> <span class="n">uniform_sample</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
  <span class="n">x0</span> <span class="o">=</span> <span class="n">normal_sample</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
  <span class="n">xt</span> <span class="o">=</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">t</span><span class="o">*</span><span class="p">(</span><span class="n">data_batch</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span>
  <span class="n">Vt</span> <span class="o">=</span> <span class="n">data_batch</span> <span class="o">-</span> <span class="n">x0</span>
  <span class="n">Wt</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="n">Vt</span> <span class="o">-</span> <span class="n">Wt</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
  <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
            
            
            






            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2023-07-15T00:00:00-05:00">Jul 15, 2023</time>

            <h4>Category</h4>
            <a class="category-link" href="/categories.html#blog-ref">Blog</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="/tags.html#flows-ref">flows
                    <span>2</span>
</a></li>
                <li><a href="/tags.html#generative-models-ref">generative models
                    <span>2</span>
</a></li>
                <li><a href="/tags.html#matching-ref">matching
                    <span>2</span>
</a></li>
            </ul>
            





            





        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>